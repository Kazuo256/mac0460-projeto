\documentclass[a4paper,11pt]{article}
\usepackage[T1]{fontenc}
\usepackage[brazilian]{babel}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage{multirow}

\title{MAC0460 - 2º semestre de 2012 \\ Relatório do Projeto}
\author{
  Wilson Kazuo Mizutani\\
  Número USP: 6797230
  \and
  Gustavo Teixeira da Cunha Coelho\\
  Número USP: 6797334
}

\begin{document}
\maketitle

\section{Decisões de projeto}

  Usamos os Detectores e Extratores que não apresentaram problema de execução,
  como incompatibilidade de formatos das matrizes, ou falhas de segmentação
  dentro da própria biblioteca do OpenCV. Os classificadores escolhemos mais
  por preferência, mas também acabamos descartando alguns pelos mesmo motivos.  

  Isso nos deixou com as seguintes possibilidades:

  \begin{itemize}
    \item Classificadores:
    \begin{itemize}
      \item[-] Normal Bayes
      \item[-] K-Nearest Neighbours
      \item[-] Decisions Tree
      \item[-] Random Trees
    \end{itemize}
    
    \item Detectores e Extratores
      \begin{itemize}
        \item Detectores usados:
          \begin{itemize}
            \item STAR
            \item SURF
            \item SIFT
            \item ORB\footnotemark
          \end{itemize}
  
        \item Adaptadores:
          \begin{itemize} 
            \item Pyramid (usamos cada detector com e sem esse adaptador)
          \end{itemize}
  
        \item Extratores usados:
          \begin{itemize} 
            \item SURF
            \item SIFT
          \end{itemize}
  
      \end{itemize}
  
  \end{itemize}
  
  \footnotetext{
    A combinação específica de detector/extrator ORB+SIFT causava falha de
    segmentação.
  }

\section{Escolha de Parâmetros}

  O único parâmetro que necessita escolha é o número de clusters do treinador de
  Bag of Words (no caso, o \verb$BOWKMeansTrainer$). Originalmente tentamos com
  1000 clusters, mas a execução demorava mais de 2 horas. Mudamos para 100 e
  fomos aumentando meio arbitrariamente. Quando notamos que os resultados saiam
  melhores e mais rápidos com 256 clusters do que com 400, optamos por 256
  clusters.

\section{Otimizações utilizadas}

  Usamos o recurso de salvar classificadores em arquivos sempre que a respectiva
  implementação permitia, para evitar que eles fossem treinados a cada vez que
  rodássemos o programa.

  Também salvamos em arquivos os vocabulários gerados para cada combinação
  detector/extrator. Eles eram o maior gargalo das execuções (alguns passavam de
  20 minutos). Como esses arquivos podiam ser aproveitados de um classificador
  para outro, ganhamos bastante tempo na hora de rodar as baterias de testes.

  Graças a isso, a parte temporalmente relevante das computações reduziram-se ao
  tempo de detecção de KeyPoints/descritores e ao de extração de histogramas,
  que só dependem da combinação detector/extrator e não do classificador usado.

\section{Resultados obtidos}

  Abaixo segue uma tabela contendo o erro máximo de um classificador dado os
  resultados dos testes. Esse erro é calculado a partir da fórmula:

  \begin{center}
    $ Erro_T(g)+Z_n * \sqrt{\frac{Erro_T(g)(1 - Erro_T(g))}{n}} $
  \end{center}

  Onde $n$ é o número de amostras de teste, $Erro_T$ é a porcentagem de erro do
  classificador e $Z_n$ é uma constante indicando o intervalo de confiança.
  Neste caso usamos um intervalo de confiança de 90\% (e consequentemente um
  $Z_n$ de 1.64), mas como tal intervalo denota o intervalo entre o erro máximo
  e o erro mínimo, consideramos apenas o erro máximo, que então é tido com 95\%
  de confiança.

  \hspace{-25pt}
  \begin{tabular}{|c|c|c|c|c|}
    \hline
     & Bayes & kNN & Random Trees & Decision Tree \\
    \hline
        STAR-SURF & 48,38\% & 77,35\% & 72,52\% & 83,57\% \\
        SURF-SURF & 23,31\% & 46,56\% & 35,29\% & 72,52\% \\
        SIFT-SURF & 53,77\% & 65,88\% & 53,77\% & 78,93\%\\
        ORB-SURF & 25,38\% & 48,38\% & 46,56\% & 70,88\% \\
        PyramidSTAR-SURF & 50,19\% & 75,75\% & 62,48\% & 77,35\% \\
        PyramidSURF-SURF & 29,41\% & 42,87\% & 42,87\% & 80,49\% \\
        PyramidSIFT-SURF & 42,87\% & 57,29\% & 46,56\% & 60,77\% \\
        PyramidORB-SURF & 19,08\% & 31,39\% & 29,41\% & 65,88\% \\
        STAR-SIFT & 21,22\% & 27,41\% & 27,41\% & 55,54\% \\
        SURF-SIFT & 27,41\% & 27,41\% & 31,39\% & 55,54\% \\
        SIFT-SIFT & 31,39\% & 50,19\% & 44,72\% & 67,56\% \\
        PyramidSTAR-SIFT & 12,35\% & 14,66\% & 23,31\% & 46,56\% \\
        PyramidSURF-SIFT & 27,41\% & 31,39\% & 27,41\% & 46,56\% \\
        PyramidSIFT-SIFT & 12,35\% & 39,11\% & 35,29\% & 64,19\% \\
        PyramidORB-SIFT & 23,31\% & 29,41\% & 21,29\% & 44,72\% \\
        
    \hline
  \end{tabular}
  \bigskip

  É fácil deduzir da tabela que o classificador Bayesiano é melhor que os outros
  três. De fato, ele foi melhor em todas as combinações de detector/extrator,
  exceto contra o Classificador Random Trees usando a combinação
  \textit{PyramidORB-SIFT}.

  Abaixo segue uma tabela do tempo total tomado para detecção de KeyPoints,
  extração de descritores e extração de histogramas. O tempo para criar o
  vocabulário e treino do classificador é ignorado aqui pois, como já
  mencionado, ambos o classificador e o vocabulário podem ser salvos em arquivos
  para uso posterior.

  \vspace{20pt}
  \hspace{65pt}
  \begin{tabular}{|c|c|c|}
    \hline
    Feature &  \multicolumn{2}{|c|}{Descriptor Extractor} \\
    \cline{2-3}
     Detectors & SURF & SIFT \\
    \hline
    STAR & 11,25 & 57 \\
    SURF & 108,5 & 524,5 \\
    SIFT  & 26 & 47,25 \\
    ORB  & 50 & X \\
    PyramidSTAR & 13,75 & 66,5 \\
    PyramidSURF & 172,75 & 1396 \\
    PyramidSIFT & 37 & 111,25 \\
    PyramidORB & 222,5 & 1634,75 \\
    \hline
  \end{tabular}
  \bigskip
  \vspace{10pt}

  Abaixo seguem as matrizes de confusão de cada um dos melhores resultados de
  combinação detector/extrator para cada um dos classificadores usados.

  \hspace{-75pt}
  \begin{tabular}{|cc|c|c|c|c|c|c|c|}
    \hline
    \multicolumn{2}{|c|}{Classificador Normal Bayes} &
    \multicolumn{6}{|c|}{Respostas do Classificador} \\
    \cline{3-8}
    \multicolumn{2}{|c|}{com PyramidSIFT + SIFT}
    & Cristo & Muralha & Panteão & Pirâmides & Taj Mahal & Torre Eiffel \\
    \hline
    \multirow{6}{*}{Classes Reais}
    & \multicolumn{1}{|c|}{Cristo} & 11 & 0 & 0 & 0 & 0 & 0 \\
    \cline{2-8}
    & \multicolumn{1}{|c|}{Muralha} & 1 & 8 & 0 & 0 & 1 & 0\\
    \cline{2-8}
    & \multicolumn{1}{|c|}{Panteão} & 0 & 0 & 8 & 0 & 0 & 0\\
    \cline{2-8}
    & \multicolumn{1}{|c|}{Pirâmides} & 0 & 1 & 0 & 8 & 1 & 0\\
    \cline{2-8}
    & \multicolumn{1}{|c|}{Taj Mahal} & 0 & 0 & 0 & 0 & 9 & 0\\
    \cline{2-8}
    & \multicolumn{1}{|c|}{Torre Eiffel} & 0 & 0 & 0 & 0 & 0 & 10\\
    \hline
  \end{tabular}
  \bigskip
  
  \hspace{-75pt}
  \begin{tabular}{|cc|c|c|c|c|c|c|c|}
    \hline
    \multicolumn{2}{|c|}{Classificador kNN} &
    \multicolumn{6}{|c|}{Respostas do Classificador} \\
    \cline{3-8}
    \multicolumn{2}{|c|}{com PyramidSTAR + SIFT}
    & Cristo & Muralha & Panteão & Pirâmides & Taj Mahal & Torre Eiffel \\
    \hline
    \multirow{6}{*}{Classes Reais}
    & \multicolumn{1}{|c|}{Cristo} & 11 & 0 & 0 & 0 & 0 & 0 \\
    \cline{2-8}
    & \multicolumn{1}{|c|}{Muralha} & 2 & 8 & 0 & 0 & 0 & 0\\
    \cline{2-8}
    & \multicolumn{1}{|c|}{Panteão} & 0 & 0 & 8 & 0 & 0 & 0\\
    \cline{2-8}
    & \multicolumn{1}{|c|}{Pirâmides} & 0 & 2 & 0 & 7 & 1 & 0\\
    \cline{2-8}
    & \multicolumn{1}{|c|}{Taj Mahal} & 0 & 0 & 0 & 0 & 9 & 0\\
    \cline{2-8}
    & \multicolumn{1}{|c|}{Torre Eiffel} & 0 & 0 & 0 & 0 & 0 & 10\\
    \hline
  \end{tabular}
  \bigskip

  \hspace{-75pt}
  \begin{tabular}{|cc|c|c|c|c|c|c|c|}
    \hline
    \multicolumn{2}{|c|}{Classificador Random Trees} &
    \multicolumn{6}{|c|}{Respostas do Classificador} \\
    \cline{3-8}
    \multicolumn{2}{|c|}{com PyramidORB + SIFT}
    & Cristo & Muralha & Panteão & Pirâmides & Taj Mahal & Torre Eiffel \\
    \hline
    \multirow{6}{*}{Classes Reais}
    & \multicolumn{1}{|c|}{Cristo} & 10 & 1 & 0 & 0 & 0 & 0 \\
    \cline{2-8}
    & \multicolumn{1}{|c|}{Muralha} & 2 & 8 & 0 & 0 & 0 & 0\\
    \cline{2-8}
    & \multicolumn{1}{|c|}{Panteão} & 0 & 0 & 8 & 0 & 0 & 0\\
    \cline{2-8}
    & \multicolumn{1}{|c|}{Pirâmides} & 2 & 2 & 0 & 6 & 0 & 0\\
    \cline{2-8}
    & \multicolumn{1}{|c|}{Taj Mahal} & 1 & 0 & 0 & 0 & 8 & 0\\
    \cline{2-8}
    & \multicolumn{1}{|c|}{Torre Eiffel} & 0 & 0 & 0 & 0 & 0 & 10\\
    \hline
  \end{tabular}
  \bigskip

  \hspace{-75pt}
  \begin{tabular}{|cc|c|c|c|c|c|c|c|}
    \hline
    \multicolumn{2}{|c|}{Classificador Decision Tree} &
    \multicolumn{6}{|c|}{Respostas do Classificador} \\
    \cline{3-8}
    \multicolumn{2}{|c|}{com PyramidORB + SIFT}
    & Cristo & Muralha & Panteão & Pirâmides & Taj Mahal & Torre Eiffel \\
    \hline
    \multirow{6}{*}{Classes Reais}
    & \multicolumn{1}{|c|}{Cristo} & 9 & 0 & 0 & 1 & 1 & 0 \\
    \cline{2-8}
    & \multicolumn{1}{|c|}{Muralha} & 9 & 0 & 0 & 1 & 0 & 0\\
    \cline{2-8}
    & \multicolumn{1}{|c|}{Panteão} & 0 & 0 & 8 & 0 & 0 & 0\\
    \cline{2-8}
    & \multicolumn{1}{|c|}{Pirâmides} & 3 & 0 & 0 & 6 & 1 & 0\\
    \cline{2-8}
    & \multicolumn{1}{|c|}{Taj Mahal} & 3 & 0 & 0 & 0 & 6 & 0\\
    \cline{2-8}
    & \multicolumn{1}{|c|}{Torre Eiffel} & 1 & 0 & 0 & 0 & 0 & 9\\
    \hline
  \end{tabular}
  \vspace{20pt}

  Uma observação que podemos fazer aqui é que, enquanto os classificadores
  Bayesiano, K-Nearest Neighbors e Random Trees obtiveram matrizes de confusão
  boas (o Bayesiano ainda sobressaindo-se), o de Decision Tree teve uma
  particularmente pior. Ele errou todas as classificações de imagens da Muralha
  da China. Provavelmente essa combinação específica de detector/extrator só foi
  a melhor dele por acaso, e mesmo assim, como é possível observar na primeira
  tabela, ainda ficou com um erro máximo de 44,72\%.

\end{document}

